# TextArena integration

This repo contains the instance generator, game master, scorer, and game specs necessary to integrate games from [TextArena](https://github.com/LeonGuertler/TextArena/tree/main) into the clem framework.

## Structure of `ta_integration` folder

The main files handling the integration are:

* `master.py`: Only contains the GameBenchmark subclass `TextArenaBenchmark`
* [ta_master.py](#gamemaster)
    * Contains the actual `TextArenaPlayer` and `TextArenaGameMaster` classes. The latter is implemented as similar as possible to `DialogueGameMaster`, and offers a number of convenience functions for sub-classing.
    * Holds most of the integration functionality. For example, `TextArenaGameMaster.step()` will both advance the TextArena environment and handle the proper clem-style logging.
    * Model calls use `TextArenaPlayer` only.
* `clem_observation_wrapper.py`: `ClemObservationWrapper` is a subclass of TextArena's `ObservationWrapper` and mostly takes care of converting the messages generated by the environment into the appropriate context format used by clem.
* [submasters.py](#gamemaster): Holds subclasses of `TextArenaGameMaster`. Most importatnt are `SinglePlayerMaster` and `TwoPlayerMaster`, which should work out of the box for all single and two player games. It also contains specific `GameMaster` subclasses for individual games, such as `WordChainsMaster`. Subclassing is mostly necessary for two reasons:
    * To ensure deterministic sampling, see [Reproducibility](#reproducibility)
    * To extract information from the TA environment before it closes, see [Logging from ta_env](#logging-taenv-values)
* [metrics.py](#scoring): Holds `GameScorer` subclasses with the main purpose of calculating the bench score
* [clemgame.json](#clemgamejson): holds game definitions and configurations. References both the TA entry point and the suitable `GameMaster` and  `GameScorer` classes (is necessary) and can hold mock player responses. Adding an entry here should be sufficient to integrate most single and two player games.
* `instancegenerator.py`: Makes sure that all difficulty levels offered by TA (or custom experiments) get their own instance(s).


## Adding games

### TextArena structure

In the TextArena repo, the game environments containing all game logic are stored in `textarena/envs`. Each env inherits from `ta.Env`, and has a game `ta.State` depending on the number of players. They can be wrapped in different ObservationWrappers for frontends or response generation.

### Automated generation of game info and clemgame templates

You can run `get_game_info.py` with the following flags to generate game info and clemgame templates automatically:
* `--game_info`: Generates `text_arena_game_info.json` with all games available in the installed TextArena version. If a prior version is present, notes from the older file will be preserved.
* `--clemgame_templates`: Generates `clemgame_templates.json` with suitable templates for all single and two player games available in the installed TextArena version
* `--get_stats`: Prints statistics on integrated games
* `--integrated_games`: Generates `ta_game_list.txt` with a list of all games already integrated in clem (i.e., present in `clemgames.json`) that can be fed into a bash script for running experiments
All of the generated files will be stored in the `notes_and_templates` folder.

The most important function is `--game_info`, which executes the following steps:
1. Check the current clembench GameRegistry for already integrated games
2. Gets all EntryPoints for all games available in the installed TextArena version and for each game:
    * skips games that are already integrated
    * ignores games that do not have a `-raw` version (i.e., cannot necessarily be used with the ClemObservationWrapper out of the box)
    * ignores games that use a `jury_class` (i.e., an LLM as judge or game master)
    * tries to import the module to see if it loads properly
    * loads the module's source code as text to check
        * if the env uses `OpenRouterAgent` (i.e., a non-player LLM)
        * the state class to determine the number of players
3. If all of the prior checks are passed, it tries to set up the environment to
    * make sure the observations match the expected format
    * extract possible commands (usually wrapped in square brackets `[]`)
4. If these tests are passed, the game is marked as integratable

Following that, you can run `--clemgame_templates` to generate suitable clemgame templates for all single and two player games that were marked as integratable in the prior step. If you want to test a game, copy the relevant entry from `clemgame_templates.json` into `ta_integration/clemgames.json`. The automatically created game name starts with `ta_` and is converted from CamelCase to snake_case, e.g. `TicTacToe` > `ta_tic_tac_toe`.

Then, you can run `clem run -g <game_name> -m human`. An instance file is automatically generated in `ta_integration/instances_<game_name>.json` and the game should start playing in the terminal. It might be necessary to adjust the `clemgame.json` entry.

### `clemgame.json`

`clemgame.json` entries for TextArena have the following basic structure:

```
{
    "game_name": "ta_tic_tac_toe",
    "description": "Classic two player game where players alternate placing Xs and Os on a 3x3 grid, aiming to get three in a row horizontally, vertically, or diagonally.",
    "entry_point": "textarena.envs.TicTacToe.env:TicTacToeEnv",
    "n_instances": 3,
    "instances": "in_tic_tac_toe",
    "players": 2
},
```
`description` is optional and has to be added manually. `n_instances` can be adjusted as needed. In the standard use case, the necessary `master` and `scorer` keys are omitted, so that the default `GameMaster` and `GameScorer` subclasses are used depending on the number of players. See [GameMaster](#gamemaster) and [Scoring](#scoring) for details.

Additionally, the following keys can be added for more control:
```
    "master": "<your custom GameMaster>",
    "scorer": "<your custom GameScorer>",
    "player_specs": [
        {
            "role": "<role name>",
            "custom_response": ["<response1>", "<response2>"]
        },
        ...
    ]
```
If you add `player_specs`, make sure that the number of entries matches `players`. The custom responses are sampled when playing with `-m mock`. The game info file should provide possible commands to choose from.

If necessary, you can also adjust the experiments used for instance generation, if the default ones provided by TA are not suitable. See [Experiments](#experiments) for details.

#### Experiments

TA defines experiments with different difficulty levels, e.g.:
`"Othello-v0-tiny", "Othello-v0-small", "Othello-v0", "Othello-v0-big", "Othello-v0-huge", "Othello-v0-hard"`
By default, all experiments specified by TA are used, but you can also provide a list in the `experiments` key in `clemgame.json`, such as:
```
"experiments": ["Othello-v0-tiny", "Othello-v0-small", "Othello-v0", "Othello-v0-big"]
```

Alternatively, you can provide a dict with experiments and configs such as:
```
"game_name": "ta_battleship",
"entry_point": "textarena.envs.Battleship.env:BattleshipEnv",
"experiments": {
    "small": {
            "grid_size": 7
    },
    "standard": {
            "grid_size": 10
    }
},
[...]
```
The config dict must match the keys found in the TA experiment definitions (see [TextArena registry](https://github.com/LeonGuertler/TextArena/blob/main/textarena/envs/__init__.py) for reference).

## GameMaster

Only subclass `GameMaster` if strictly necessary. Single and Two player games should work out of the box. Reasons for subclassing are mostly reproducibility, and logging values from the env.

There are three standard hooks that can be used to add functionality:
* `_on_before_reset()`, which is called after the env is created, but before the game is initialized,
* `_on_before_game()`, which is called after the game is set up,
* and the abstract method `_on_after_game()`, which is called with the rewards passed from TA. Subclasses should log `METRIC_ABORT`, `METRIC_SUCCESS`, and `METRIC_LOSE` here.

### Reproducibility

Despite passing the seed, there might occur some non-deterministic behavior, which might be fixed by subclassing `GameMaster`.

For example, in WordChains, the start word is sampled from a list generated from a set, which is non-deterministic. So, `WordChainsMaster` sorts it in `_on_before_reset()`.

`Minesweeper` only distributes the mines after the first move. Thus, the custom game maste simulates the first move in `_on_before_game()`, which is always opening the most central cell.

### Logging ta_env values

All values needed for scoring or evaluation must be extracted from the env before it closes.
For example, `WordChainsMaster` logs `start_word` and `start_word_length` in `_on_before_game()`, and `end_word`, `end_word_length` and `word_length_diff` in `_on_after_game`.

## Scoring

Scoring is somewhat difficult and depends on the game and number of players. `rewards = env.close()` usually gives a good starting point.

### Single Player

In single player games, `rewards` contains a numeric value that usually takes on of the following values:
* `-1` means aborted (NOTE: as of August 2025, single player games never return `-1`, likely a bug)
* `1` means success
* a float in the interval $[0,1]$, e.g. if a game was terminated by exceeding turn limit. Usually calculated by a `ta_env._get_percentage_completion()`
In the latter two cases, the reward can be the basis for calculating the Main Score.

`SinglePlayerScorer` simply logs `reward * 100` as Main Score (if `>=0`).


### Two Player

Some games, such as Word Chains, can be interpreted as collaborative, so we can base scoring on the length of the final word in the chain.

Most games, however, are competitive and only give the rewards win (`1`) or lose (`-1`).
These scores are simply logged as `ta_reward`, and now meaningful Main Score can be calculated.